{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "FEED-FORWARD NEURAL NETWORK"
      ],
      "metadata": {
        "id": "R1ah_IZIulZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF3JcnKYnwsb",
        "outputId": "784776a0-dfaa-4af4-f84b-4b5623a555bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.5865\n",
            "Epoch [20/50], Loss: 0.5137\n",
            "Epoch [30/50], Loss: 0.4365\n",
            "Epoch [40/50], Loss: 0.3588\n",
            "Epoch [50/50], Loss: 0.2883\n",
            "Feedforward NN Accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#step1...split_data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#step2...Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#step3...convert_to_torch_tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "#step4...create feedforward_NN, {activation_factors- ReLU and Sigmoid}\n",
        "class FeedForwardNN(nn.Module):    #create_class_nd_make_layered_neurons\n",
        "    def __init__(self, input_dim):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)  # Input -> Hidden Layer (32 neurons)\n",
        "        self.fc2 = nn.Linear(32, 16)         # Hidden -> Hidden (16 neurons)\n",
        "        self.fc3 = nn.Linear(16, 1)          # Hidden -> Output (1 neuron for binary classification)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))  # Output probability\n",
        "        return x\n",
        "model = FeedForwardNN(X_train.shape[1])\n",
        "\n",
        "#step5... optimizer$loss\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  #adam_optimizer\n",
        "\n",
        "#step6....train_the_model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "#step6....evaluate_the_model\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test)\n",
        "    y_pred_cls = (y_pred >= 0.5).float()\n",
        "    acc = accuracy_score(y_test, y_pred_cls)\n",
        "    print(f\"Feedforward NN Accuracy: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step1.....Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "#step2...develop_the_CNN_Architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) # 1 input channel, 16 filters\n",
        "        self.pool = nn.MaxPool2d(2, 2)                         # 2x2 pooling\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32*7*7, 128)                      # Fully connected\n",
        "        self.fc2 = nn.Linear(128, 10)                          # Output 10 classes (digits)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 32*7*7)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "# step3....Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# step4....Train\n",
        "for epoch in range(1):\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch+1}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# step5..... Evaluate_the_model\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"CNN Accuracy: {100*correct/total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myuh0excuslv",
        "outputId": "c625dd52-d200-40ad-f203-f2d7ebd313c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 59.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.73MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.45MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Loss: 0.1535\n",
            "CNN Accuracy: 97.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECURRENT NEURAL NETWORK"
      ],
      "metadata": {
        "id": "Hzu6TtBnxUUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# step1......Generate sine wave data\n",
        "x = np.linspace(0, 100, 500)\n",
        "y = np.sin(x)\n",
        "\n",
        "#step2....Prepare sequences\n",
        "def create_sequences(data, seq_length=10):\n",
        "    xs, ys = [], []\n",
        "    for i in range(len(data)-seq_length):\n",
        "        xs.append(data[i:i+seq_length])\n",
        "        ys.append(data[i+seq_length])\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X_seq, y_seq = create_sequences(y, seq_length)\n",
        "X_seq = torch.tensor(X_seq, dtype=torch.float32).unsqueeze(-1) # shape (samples, seq_len, 1)\n",
        "y_seq = torch.tensor(y_seq, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "#ste3...build_rnn_archi\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=32, num_layers=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :]) # last time step\n",
        "        return out\n",
        "#step4....optimizer&loss\n",
        "model = RNNModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "#step5...train&evaluate\n",
        "for epoch in range(100):\n",
        "    outputs = model(X_seq)\n",
        "    loss = criterion(outputs, y_seq)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayvIF2GLsYxI",
        "outputId": "31ec9d6a-da32-4e4a-c087-6d2be1934e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/100], Loss: 0.0047\n",
            "Epoch [40/100], Loss: 0.0004\n",
            "Epoch [60/100], Loss: 0.0002\n",
            "Epoch [80/100], Loss: 0.0001\n",
            "Epoch [100/100], Loss: 0.0001\n"
          ]
        }
      ]
    }
  ]
}